Original Feature


    - sales_train.csv (Daily historical data from January 2013 to October 2015)
        - data_block_num
        - shop_id
			* some shops occur many times and some other shops occur few times
			* 60 unique shops
		- item_id
			* 21807 unique items
		- item_price 
			* There can be outlier
			* -1 could be representation of null
			* item_price could be set in relatively same item_price
		- item_count_day
			* number of products sold at the day
			* There can be outlier
			* It could be heavily dependent on item
			* check if it is returned or not


	- test.csv (forecast the sales for shops and products for November 2015)
		- ID
			* 214200 unique pair
		- shop_id
			* 42 unique shops
			* 0 new shops
		- item_id
			* 5100 unique items
			* 363 new items
   
	- items.csv
		- item_id
		- item_category_id
			* 22170 unique items

	- shops.csv
		- shop_name
			* starts with the city name
		- shop_id
			* 60 unique shops

	- item_categories.csv
		- item_category_name
			* contains "type" and "subtype"
		- item_category_id
			* 84 unique item_categories

Comment
	- Predict number of total sales corresponding to items in each shop soled in Nov 2015
    - lag feature can be created 
		- 
Todos
	- create lag features
		- simple target lag feature
			- lag of item_cnt_month
			- lag of item_total_price
			- 1, 2, 3, 6, 12 months 
				- (we are taking lag of far past, because the same item and shop does not occur frequently )
		- Mean encoded features for each month
		    - Simple mean encoding
				- Lag feature of average of value for each month (date_block_num)
					- item_cnt_month
					- lag: 1 month
				- Lag feature of average of value for each items in the month (date_block_num * item_id)
					- item_cnt_month
					- lag: 1, 2, 3, 6. 12 month
				- Lag feature of average of value for each shops in the month (date_block_num * shop_id) 
					- item_cnt_month
					- lag: 1, 2, 3, 6, 12 month
				- Lag feature of average of value for each item_categories in the month  (date_block_num * item_category_id)
					- item_cnt_month
					- lag: 1, 2, 3, 6, 12 month
				- Lag feature of average of value for each item type in the month  (date_block_num * type_code)
					- item_cnt_month
					- lag: 1 month
				- Lag feature of average of value for each item subtype in the month  (date_block_num * subtype_code)
					- item_cnt_month
					- lag: 1 month
				- Lag feature of average of value for each city in the month  (date_block_num * city_code)
					- item_cnt_month
					- lag: 1 month
			- Combination mean encoding
				- Lag feature of average of value for each combination of shop and item_category in the month (date_block_num * shop_id * item_category_id) 
				    - item_cnt_month
					- lag: 1 month
				- Lag feature of average of value for each combination of shop and item type in the month (date_block_num * shop_id * type_code)
					- item_cnt_month
					- lag: 1 month 
				- Lag feature of average of value for each combination of shop and item subtype in the month (date_block_num * shop_id * subtype_code)
					- item_cnt_month
					- lag: 1 month 
				- Lag feature of average of value for each combination of item and  city in the month (date_block_num * item_id * city_code)
					- item_cnt_month
					- lag: 1 month 	
	- create trend feature for price
	- calculate 'revenue' (item_price * item_cnt_day) on sales_train file 
	- create feature related to month and use month as key to merge it
	- find out validation strategy
	- create scaled dataset additionally
	- create binning feature
		- ex) item_total_price: 
	- search how to deal with outlier rather than removing it
	

Done
	- deal with outlier in item_price and item_cnt_day	
		- use item_price <= 100000
		- use item_cnt_day <= 1000
	- replace negative values in item_price in sales_train with median
		- there is only one -1 in item_price 
		- simply replacing with median can work
	- generatetrain data for each month
		- generate day, date, month feature
		- aggregate item_price and item_cnt_day by item_id, shopi_id, and month
	- create training dataset similar to test dataset
		- create all pair of shops and items occurred in the month